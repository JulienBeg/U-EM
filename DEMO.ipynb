{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unprofiled Expectation Maximisation\n",
    "\n",
    "This notebook is used to show how the **Unprofiled Expectation Maximization** can be used in practice.\n",
    "\n",
    "This presents practically the work of **TO COMPLETE IF ACCEPTED**\n",
    "                            \n",
    "This is a joint work with:\n",
    " * Julien Béguinot (Télécom Paris, Institut Polytechnique de Paris)\n",
    " * Wei Cheng (Secure-IC S.A.S, Télécom Paris, Institut Polytechnique de Paris)\n",
    " * Sylvain Guilley (Secure-IC S.A.S, Télécom Paris, Institut Polytechnique de Paris)\n",
    " * Olivier Rioul (Télécom Paris, Institut Polytechnique de Paris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation of Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sbox\n",
    "\n",
    "Computation of the Substitution Box and Hamming Weight\n",
    " * DES Sbox\n",
    " * PRESENT Sbox\n",
    " * SubByte from AES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_repr_vec = np.vectorize(np.binary_repr)\n",
    "hw = np.char.count\n",
    "\n",
    "def Sbox_(b):\n",
    "    \n",
    "    \"\"\"\n",
    "    # 1st line of 1st DES Sbox (can be critized as an NSA cipher, which non-formalized security proof) \n",
    "    # https://en.wikipedia.org/wiki/S-box\n",
    "    S = np.array([2,12,4,1,7,10,11,6,8,5,3,15,13,0,14,9],dtype=np.uint8) \n",
    "    \"\"\"\n",
    "    \n",
    "    # PRESENT\n",
    "    S = np.array([0xC, 0x5, 0x6, 0xB, 0x9, 0x0, 0xA, 0xD, 0x3, 0xE, 0xF, 0x8, 0x4, 0x7, 0x1, 0x2],dtype=np.uint8)\n",
    "\n",
    "    # SubBytes look-up-table (AES)\n",
    "    \"\"\"\"\n",
    "    S = np.array([\n",
    "    0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5, 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76,\n",
    "    0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0, 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0,\n",
    "    0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc, 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15,\n",
    "    0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a, 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75,\n",
    "    0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0, 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84,\n",
    "    0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b, 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf,\n",
    "    0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85, 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8,\n",
    "    0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5, 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2,\n",
    "    0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17, 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73,\n",
    "    0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88, 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb,\n",
    "    0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c, 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79,\n",
    "    0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9, 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08,\n",
    "    0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6, 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a,\n",
    "    0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e, 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e,\n",
    "    0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94, 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf,\n",
    "    0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68, 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16 ],dtype=np.uint8)\n",
    "    \"\"\"\n",
    "\n",
    "    return S[b]\n",
    "\n",
    "Sbox = np.vectorize(Sbox_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.arange(2**4,dtype = np.uint8)\n",
    "N = 4\n",
    "Nparams = int(N*(N+1)/2) + 1\n",
    "\n",
    "#If you target the DPAv4.2 contests. \n",
    "#mask = np.array([3,12,53,58,80,95,102,105,150,153,160,175,197,202,243,252],dtype= np.uint8)\n",
    "#def Mask_(b):\n",
    "#    return mask[b]\n",
    "#Mask = np.vectorize(Mask_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Trace Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 200          # Number of Traces\n",
    "sigma=1          # Level of Noise\n",
    "sigma_a = .8     # Level of epistemic Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw secret keys, masks, plaintext randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected secret key is :  9\n"
     ]
    }
   ],
   "source": [
    "secret_k = np.random.randint(0,2**N)                  #The secret key\n",
    "T = np.random.randint(0,2**N,Q ,dtype=np.uint8)       #The plaintext\n",
    "Mask = np.random.randint(0,2**N,Q ,dtype=np.uint8)    #The Mask\n",
    "\n",
    "print(\"The selected secret key is : \",secret_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw random leakage parameters for the quadratic leakage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "secretC0 =  np.ones(Nparams) + sigma_a * np.random.randn(Nparams)\n",
    "secretC0 *= np.sqrt(Nparams) / norm(secretC0)\n",
    "\n",
    "secretC1 = np.ones(Nparams) + sigma_a * np.random.randn(Nparams)\n",
    "secretC1 *= np.sqrt(Nparams) / norm(secretC1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw random Additive White Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise0 = sigma * np.random.randn(Q)\n",
    "Noise1 = sigma * np.random.randn(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Sensitive Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.unpackbits(Sbox(np.uint8(secret_k)^T)^Mask).reshape((Q,8))[:,8-N:8]\n",
    "X0 = np.unpackbits(Mask).reshape((Q,8))[:,8-N:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the  noisy leakages with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = np.einsum(\"qj,ji,qi->q\",X0,vec_to_sym(secretC0[0:Nparams-1]),X0) + secretC0[Nparams-1]\n",
    "Y0 += Noise0\n",
    "\n",
    "Y1 = np.einsum(\"qj,ji,qi->q\",X1,vec_to_sym(secretC1[0:Nparams-1]),X1) + secretC1[Nparams-1]\n",
    "Y1 += Noise1\n",
    "\n",
    "Y = np.array([Y0,Y1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinguishers \n",
    "\n",
    "### 2O-CPA : Second Order Corelation Power Analysis\n",
    "\n",
    "* This distinguisher ranks the key hypothesis by deacreasing Pearsons correlation coefficient in between the model and the traces.\n",
    "* The combination function is the classical centered product of the traces.\n",
    "\n",
    "A reference : *\"Emmanuel Prouff, Matthieu Rivain, and Régis Bevan. Statistical Analysis of Second\n",
    "Order Differential Power Analysis. IEEE Trans. Computers\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HO_CPA(T,Y):\n",
    "\n",
    "    Q = len(T)\n",
    "    Text,Mask = np.meshgrid(T, M, copy=False, sparse=True)\n",
    "\n",
    "    ybar = np.reshape(np.mean(Y,axis=1),(2,1))\n",
    "    Yp = np.prod(Y - ybar,axis=0) #Belong to R^Q\n",
    "\n",
    "    Pearsons = np.zeros(2 ** N)\n",
    "\n",
    "    mu_y = np.mean(Yp) #Precompute the mean\n",
    "    for k in range(2**N):\n",
    "\n",
    "        X = (hw(binary_repr_vec(Sbox(k^Text)^Mask),'1')-N/2)*(hw(binary_repr_vec(Mask),'1')-N/2)\n",
    "        mu_x = np.mean(X)\n",
    "        std_x = np.std(X)\n",
    "\n",
    "        if std_x == 0:\n",
    "            print(\"Warn on cpa with 0 variance\")\n",
    "            return np.arange(16)\n",
    "\n",
    "        mu_y = np.mean(Yp)\n",
    "        cov = np.mean((Yp-mu_y )* (X-mu_x))\n",
    "        Pearsons[k] = abs(cov) / std_x\n",
    "\n",
    "    k_guess = np.argsort(-Pearsons)\n",
    "    return k_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the distinguisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The secret key is ranked  0  by the distinguisher.\n"
     ]
    }
   ],
   "source": [
    "k_guess = HO_CPA(T,np.copy(Y))\n",
    "\n",
    "print(\"The secret key is ranked \", np.argmax(k_guess == secret_k), \" by the distinguisher.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-EM-HAM\n",
    "\n",
    "* This distinguisher regress the parameters of of a stochastic attack on the fly. Then it ranks the different key hypothesis by decreasing goodness of fit.\n",
    "* The leakage model considered is the Hamming Weight of the sensitive variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Subfonction used in the maximization step of the U-EM with HW leakage model.\n",
    "\n",
    "Input:\n",
    "    beta : posterior probabilities for each masks and keys\n",
    "    X    : sensitive varioables of the model\n",
    "    Y    : leakage\n",
    "    Q    : number of traces\n",
    "\n",
    "Output;\n",
    "    na,b : parameters that maximizes the goodness of fit\n",
    "\"\"\"\n",
    "def minimize_u(beta,X,Y,Q):\n",
    "    x_tilde = np.sum(beta * X, axis = 0).T #Should belong to R^Q\n",
    "    x_bar = np.mean(x_tilde,axis = 0) #Should belong to R\n",
    "    var_x = (np.sum(beta * (X-x_bar) ** 2) / Q)\n",
    "    cov = np.sum(beta * (X-x_bar) *Y) / Q\n",
    "    na = cov / var_x\n",
    "    b = - na * x_bar\n",
    "    return na,b\n",
    "\n",
    "\"\"\"\n",
    "This implements the U-EM-HAM algorithm described in the article.\n",
    "\n",
    "Input:\n",
    "    T         : the plaintext used for the considered Traces\n",
    "    Y         : the two shares of the leakage\n",
    "    sigma     : the noise level\n",
    "    tolerance : a threshold to decide when to stopp the while loop\n",
    "\n",
    "Output:\n",
    "    k_guess   : the key hypothesis ranked by deacreasing goodness of fit with the model\n",
    "\"\"\"\n",
    "def EM_bivarie_2(T,Y,sigma=np.reshape(np.array([1,1]),(2,1)),tolerance=10**-10):\n",
    "\n",
    "    Q = len(T)\n",
    "\n",
    "    #Normalisation and centering\n",
    "    Y/=(2 ** .5 * sigma)\n",
    "    y_bar = np.reshape(np.mean(Y,axis=1),(2,1)) #Precompute the average of the traces\n",
    "    Y-=y_bar\n",
    "    Y = np.reshape(Y,(2,1,Q))\n",
    "\n",
    "    LL = np.zeros(2**N) #To store the log-likelihood of each key hypothesis\n",
    "\n",
    "    Text,Mask = np.meshgrid(T, M, copy=False, sparse=True)\n",
    "\n",
    "    X0 = np.reshape(np.char.count(binary_repr_vec(Mask), '1'),(len(Mask),1))\n",
    "\n",
    "    for k in range(2**N):\n",
    "        a1,a2 = 1,1\n",
    "        b1,b2 = 0,0\n",
    "\n",
    "        X1 = np.char.count(binary_repr_vec(Sbox(k^Text)^Mask), '1')\n",
    "\n",
    "        stop = False\n",
    "        while not stop:\n",
    "\n",
    "            #The E Step\n",
    "            Norm =(Y[0]-a1*X0-b1)**2 + (Y[1]-a2*X1-b2)**2\n",
    "            C = np.min(Norm,axis=0) #For numerical stabiblity of the exponnetia\n",
    "            beta = np.exp(C-Norm)\n",
    "            S  = np.sum(beta,axis=0) #Normalisation coefficient\n",
    "            beta = beta / S #Normalised p.m.f\n",
    "\n",
    "            #The M Step\n",
    "            na1,b1 = minimize_u(beta,X0,Y[0],Q)\n",
    "            na2,b2 = minimize_u(beta,X1,Y[1],Q)\n",
    "\n",
    "            #Does the new values of a and b changed up to a certain tolerance level ?\n",
    "            stop = abs(na1-a1) + abs(na2-a2) < tolerance\n",
    "\n",
    "            a1,a2 = na1,na2\n",
    "\n",
    "        LL[k] = np.sum(np.log(S)) - np.sum(C) #Store the log-likelihood of the key\n",
    "    k_guess = np.argsort(-LL)\n",
    "    return k_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The secret key is ranked  0  by the distinguisher.\n"
     ]
    }
   ],
   "source": [
    "k_guess = EM_bivarie_2(T,np.copy(Y),sigma=np.reshape(np.array([sigma,sigma]),(2,1)),tolerance=10**-10)\n",
    "\n",
    "print(\"The secret key is ranked \", np.argmax(k_guess == secret_k), \" by the distinguisher.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-EM-LIN\n",
    "\n",
    "* This distinguisher regress the parameters of of a stochastic attack on the fly. Then it ranks the different key hypothesis by decreasing goodness of fit.\n",
    "* The leakage model considered is a linear combination of the bits of the sensitive variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_ridge(beta,X,Y,Mask,Q,N,lamb =10**2):\n",
    "        \n",
    "    XX = np.sum(X,axis=2)\n",
    "    x_tilde = np.sum(beta * XX, axis = 0).T #Should belong to R^Q\n",
    "    x_bar = np.mean(x_tilde,axis = 0) #Should belong to R\n",
    "\n",
    "    var_x = np.sum(beta * (XX-x_bar) ** 2)\n",
    "    cov = np.sum(beta * (XX-x_bar) *Y)\n",
    "\n",
    "    na = cov / var_x * np.ones(N)\n",
    "\n",
    "    x_tilde = np.sum(np.transpose(X,axes=(2,0,1)) * beta, axis = 1).T #Should belong to R^(QxN)\n",
    "    x_bar = np.mean(x_tilde,axis = 0) #Should belong to R^N\n",
    "\n",
    "    X_cent = np.reshape(X - x_bar,(len(Mask),Q,N,1))\n",
    "\n",
    "    AutoCorr = np.einsum('mq,mqtp->tp' , beta,np.einsum('ijkl,ijhl->ijkh', X_cent,X_cent))  + Q *  lamb * np.eye(N)\n",
    "    X_cent = np.reshape(X_cent,(len(Mask),Q,N))\n",
    "\n",
    "    RelCorr = np.einsum('qm,q->m' ,  x_tilde ,np.reshape(Y - np.dot(x_tilde-x_bar,na),(Q)))  #Since Y is centered no need to sub x_bar to x_tilde\n",
    "\n",
    "    na += np.linalg.solve(AutoCorr,RelCorr)\n",
    "    #na += np.linalg.lstsq(AutoCorr,RelCorr,rcond=None)[0]\n",
    "    nb = - np.dot(x_bar,na)\n",
    "\n",
    "    return na,nb\n",
    "\n",
    "\n",
    "def EM_BIV_LIN_RIDGE(T,Y,N=4,tolerance=10**-8,sigma=np.reshape(np.array([1,1]),(2,1))):\n",
    "        \n",
    "        t1 = time()\n",
    "        lamb = 1/(2 * sigma_a ** 2)\n",
    "        Q = len(T)\n",
    "\n",
    "        Y/=(2 ** .5 * sigma)\n",
    "        y_bar = np.reshape(np.mean(Y,axis=1),(2,1)) #Precompute the average of the traces\n",
    "        Y-=y_bar\n",
    "        sigma_y=np.std(Y,axis=1)\n",
    "\n",
    "        LL = np.zeros(2**N) #To store the log-likelihood of each key hypothesis\n",
    "\n",
    "        #M = np.array([3,12,53,58,80,95,102,105,150,153,160,175,197,202,243,252],dtype = np.uint8)\n",
    "        Text,Mask = np.uint8(np.meshgrid(T, M))\n",
    "\n",
    "        X2 = np.reshape(np.unpackbits(Mask),(2**N,Q,8))[:,:,8-N:8]\n",
    "\n",
    "        for k in range(2**N):\n",
    "            \n",
    "            #a_1,b_1 = np.ones(N) * np.abs( sigma_y[0] ** 2 - sigma[0] **2) ** .5 * np.sqrt(4/N),0\n",
    "            #a_2,b_2 = np.ones(N) * np.abs( sigma_y[1] ** 2 - sigma[1] **2) ** .5 * np.sqrt(4/N),0\n",
    "            a_1,b_1 = np.ones(N),0\n",
    "            a_2,b_2 = np.ones(N),0\n",
    "\n",
    "            X1 = np.reshape(np.unpackbits(Sbox(k^Text)^Mask),(2**N,Q,8))[:,:,8-N:8]\n",
    "\n",
    "            stop = False                                                                  \n",
    "            while not stop:\n",
    "                #The E Step\n",
    "                Norm = (Y[0,:]-np.dot(X1,a_1)-b_1)**2+(Y[1,:]-np.dot(X2,a_2)-b_2)**2\n",
    "                C = np.min(Norm,axis=0) #For numerical stabiblity of the exponnetial\n",
    "                beta = np.exp(C-Norm)\n",
    "                S  = np.sum(beta,axis=0) #Normalisation coefficient\n",
    "                beta = beta / S #Normalised p.m.f\n",
    "\n",
    "                #The M Step\n",
    "                na1,b_1 = minimize_ridge(beta,X1,Y[0,:],Mask,Q,N,lamb=lamb)\n",
    "                na2,b_2 = minimize_ridge(beta,X2,Y[1,:],Mask,Q,N,lamb=lamb)\n",
    "\n",
    "                #Have a and b changed up to a certain tolerance level ?\n",
    "                diff = np.linalg.norm(na1-a_1)**2  + np.linalg.norm(na2-a_2)**2\n",
    "                stop = (diff < tolerance)\n",
    "                \n",
    "                a_1,a_2 = na1,na2\n",
    "                #print(a_1)\n",
    "                \n",
    "            LL[k] = np.sum(np.log(S)) - np.sum(C) #Store the log-likelihood of the key\n",
    "            \n",
    "        k_guess = np.argsort(-LL)\n",
    "        \n",
    "        t2 = time()\n",
    "        \n",
    "        return k_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the distinguisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The secret key is ranked  0  by the distinguisher.\n"
     ]
    }
   ],
   "source": [
    "k_guess = EM_bivarie_2(T,np.copy(Y),sigma=np.reshape(np.array([sigma,sigma]),(2,1)),tolerance=10**-10)\n",
    "\n",
    "print(\"The secret key is ranked \", np.argmax(k_guess == secret_k), \" by the distinguisher.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-EM-QUAD\n",
    "\n",
    "* This distinguisher regress the parameters of of a stochastic attack on the fly. Then it ranks the different key hypothesis by decreasing goodness of fit.\n",
    "* The leakage model considered is a quadratic function of the bits of the sensitive variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Subfonction used for the U-EM-QUAD\n",
    "Input:\n",
    "    Cvec : a list of Nparams - 1 parameters\n",
    "Output:\n",
    "    sym  : an upper trangular matrix where the parameters are layed out\n",
    "\"\"\"\n",
    "def vec_to_sym(Cvec):\n",
    "    pos = 0\n",
    "    sym = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        sym[i,i:] =  Cvec[pos:pos+N-i]\n",
    "        pos+=N-i\n",
    "    return sym\n",
    "\n",
    "\"\"\"\n",
    "Another subfonction that does the inverse of the previous one.\n",
    "(with some extra dimension at the begining)\n",
    "\"\"\"\n",
    "def matrix_to_vec(to_be_vec,m,q):\n",
    "    pos = 0\n",
    "    vec = np.zeros((m,q,Nparams-1))\n",
    "    for i in range(N):\n",
    "        vec[:,:,pos:pos+N-i] = to_be_vec[:,:,i,i:N]\n",
    "        pos+=N-i\n",
    "    return vec\n",
    "\n",
    "\"\"\"\n",
    "Subfonction that evaluates a quadratic form with design matrix C at the vector X.\n",
    "\"\"\"\n",
    "def evaluate(C,X):\n",
    "    return np.einsum(\"mqj,ji,mqi->qm\",X,vec_to_sym(C[0:Nparams-1]),X) + C[Nparams-1]\n",
    "\n",
    "\"\"\"\n",
    "This implements the U-EM-QUAD as described in the article.\n",
    "\n",
    "Input :\n",
    "    T          :  the plaintext used with the considered traces\n",
    "    Y          :  the leakages\n",
    "    sigma      :  the noise level\n",
    "    regu       :  the constant used for regression ridge\n",
    "    tolerance  :  threshold to decide when to stop the while loop\n",
    "\n",
    "Output:\n",
    "    k_guess    : the key hypothesis ranked by deacreasing goodness of fit with the model.\n",
    "\"\"\"\n",
    "def EM_quadratic(T,Y,sigma=np.reshape(np.array([1,1]),(2,1)),regu = 1,tolerance=5*10**-3):\n",
    "\n",
    "    Q = len(T)\n",
    "\n",
    "    #Normalisation and centering\n",
    "    Y/=(2 ** .5 * sigma)\n",
    "\n",
    "    ones = np.ones(Nparams) / (2 ** .5 * sigma[0])\n",
    "\n",
    "    sigma_y = np.std(Y,axis=1)\n",
    "    y_bar = np.reshape(np.mean(Y,axis=1),(2,1)) #Precompute the average of the traces\n",
    "    Y-=y_bar\n",
    "    Y = Y.reshape((2,Q))\n",
    "\n",
    "    LL = np.zeros(2**N) #To store the log-likelihood of each key hypothesis\n",
    "\n",
    "    #Text,Mask = np.meshgrid(T, M, copy=False, sparse=True)\n",
    "    Text,Mask = np.meshgrid(T,M, copy = False)\n",
    "\n",
    "    X0 = np.unpackbits(Mask).reshape((2**N,Q,8))[:,:,8-N:8]\n",
    "    X0vec = np.ones((2**N,Q,Nparams))\n",
    "    X0vec[:,:,0:Nparams-1] = matrix_to_vec(np.einsum(\"abn,abm->abnm\",X0,X0),2**N,Q)\n",
    "    X0vec = X0vec.transpose((1,0,2))\n",
    "\n",
    "    for k in range(2**N):\n",
    "\n",
    "        Cvec0 = np.copy(ones)\n",
    "        Cvec1 = np.copy(ones)\n",
    "\n",
    "        X1 = np.unpackbits(Sbox(k^Text)^Mask).reshape((2**N,Q,8))[:,:,8-N:8]\n",
    "        X1vec = np.ones((2**N,Q,Nparams))\n",
    "        X1vec[:,:,0:Nparams-1] = matrix_to_vec(np.einsum(\"abn,abm->abnm\",X1,X1),2**N,Q)\n",
    "        X1vec = X1vec.transpose((1,0,2))\n",
    "\n",
    "        last_ll = 10**4 #dummy init\n",
    "\n",
    "        stop = False\n",
    "        maxiter = 15\n",
    "        niter = 0\n",
    "        while (not stop) and (niter < maxiter):\n",
    "\n",
    "            niter += 1\n",
    "\n",
    "            # Precompute the Quadratic Form\n",
    "            f0 = evaluate(Cvec0,X0).reshape((Q,2**N))\n",
    "            f1 = evaluate(Cvec1,X1).reshape((Q,2**N))\n",
    "\n",
    "            #The E Step\n",
    "            Norm =  (Y[0].reshape((Q,1)) - f0)**2\n",
    "            Norm += (Y[1].reshape((Q,1)) - f1)**2 #Shape (Q,2**N)\n",
    "\n",
    "            #For numerical stabiblity of the exponential\n",
    "            Cc = np.min(Norm,axis=1).reshape((Q,1))#Most likely mask for each trace\n",
    "\n",
    "            #Compute pdf with Bayes\n",
    "            beta = np.exp(Cc-Norm) #Gaussian Kernel with shape (Q,2**N)\n",
    "            S  = np.sum(beta,axis=1) #Normalisation coefficient in Bayes\n",
    "            beta = beta / S.reshape((Q,1))#Normalised p.m.f\n",
    "\n",
    "            #The M Step\n",
    "            def objective0(Cvec):\n",
    "                return np.sum(beta * (Y[0].reshape((Q,1)) - evaluate(Cvec,X0).reshape((Q,2**N))) ** 2) + regu * Q * norm(Cvec-ones)\n",
    "\n",
    "            def jac0(Cvec):\n",
    "                return - 2 * np.sum(beta.reshape((Q,2**N,1)) * (Y[0].reshape((Q,1,1)) - evaluate(Cvec,X0).reshape((Q,2**N,1))) * X0vec,axis=(0,1)) + regu * 2 * Q * (Cvec-ones)\n",
    "\n",
    "            def objective1(Cvec):\n",
    "                return np.sum(beta * (Y[1].reshape((Q,1)) - evaluate(Cvec,X1).reshape((Q,2**N))) ** 2) + regu *  Q * norm(Cvec-ones)\n",
    "            def jac1(Cvec):\n",
    "                return - 2 * np.sum(beta.reshape((Q,2**N,1)) * (Y[1].reshape((Q,1,1)) - evaluate(Cvec,X1).reshape((Q,2**N,1))) * X1vec,axis=(0,1)) + regu * 2 * Q * (Cvec-ones)\n",
    "\n",
    "            #Update parameters\n",
    "            Cvec0 = minimize(objective0,Cvec0,method=\"BFGS\",jac=jac0,options={'gtol': 1e-04, 'maxiter': 10}).x\n",
    "            Cvec1 = minimize(objective1,Cvec1,method=\"BFGS\",jac=jac1,options={'gtol': 1e-04, 'maxiter': 10}).x\n",
    "\n",
    "            #Does the new values of a and b changed up to a certain tolerance level ?\n",
    "            ll = ((np.sum(np.log(S)) - np.sum(Cc))/Q)\n",
    "            stop = np.abs(ll-last_ll) < tolerance\n",
    "\n",
    "            #Store obtained goodness of fit\n",
    "            last_ll = ll\n",
    "\n",
    "        LL[k] = np.sum(np.log(S)) - np.sum(Cc) #Store the log-likelihood of the key\n",
    "\n",
    "    k_guess = np.argsort(-LL)\n",
    "\n",
    "    return k_guess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the distinguisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The secret key is ranked  0  by the distinguisher.\n"
     ]
    }
   ],
   "source": [
    "k_guess = EM_bivarie_2(T,np.copy(Y),sigma=np.reshape(np.array([sigma,sigma]),(2,1)),tolerance=10**-10)\n",
    "\n",
    "print(\"The secret key is ranked \", np.argmax(k_guess == secret_k), \" by the distinguisher.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template HAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This implements the  template attack with Hamming model.\n",
    "\n",
    "Input:\n",
    "    T         : the plaintext used for the considered Traces\n",
    "    Y         : the two shares of the leakage\n",
    "    sigma     : the noise level\n",
    "    tolerance : a threshold to decide when to stopp the while loop\n",
    "    N         : number of bits targeted\n",
    "    a_1,...   : parameters of the template to use\n",
    "\n",
    "Output:\n",
    "    k_guess   : the key hypothesis ranked by deacreasing goodness of fit with the model\n",
    "\"\"\"\n",
    "def template_ham(T,Y,sigma=np.reshape(np.array([1,1]),(2,1)),a_1=1,b_1=0,a_2=1,b_2=0,N=4):\n",
    "\n",
    "    t1 = time()\n",
    "\n",
    "    a1=a_1/(2 ** .5 * sigma[0])\n",
    "    a2=a_2/(2 ** .5 * sigma[1])\n",
    "    b1=b_1/(2 ** .5 * sigma[0])\n",
    "    b2=b_2/(2 ** .5 * sigma[1])\n",
    "\n",
    "    Q = len(T)\n",
    "\n",
    "    Y/=(2 ** .5 * sigma)\n",
    "    Y = np.reshape(Y,(2,1,Q))\n",
    "\n",
    "\n",
    "    LL = np.zeros(2**N) #To store the log-likelihood of each key hypothesis\n",
    "\n",
    "    Text,Mask = np.meshgrid(T, M, copy=False, sparse=True)\n",
    "\n",
    "    X1 = np.reshape(np.char.count(binary_repr_vec(Mask), '1'),(len(Mask),1))\n",
    "\n",
    "    for k in range(2**N):\n",
    "\n",
    "        X0 = np.char.count(binary_repr_vec(Sbox(k^Text)^Mask), '1')\n",
    "\n",
    "        Norm =(Y[0]-a1*X0-b1)**2 + (Y[1]-a2*X1-b2)**2\n",
    "\n",
    "        C = np.min(Norm,axis=0) #For numerical stabiblity of the exponnetial\n",
    "        beta = np.exp(C-Norm)\n",
    "        S  = np.sum(beta,axis=0) #Normalisation coefficient\n",
    "        beta/=S #Normalised p.m.f\n",
    "\n",
    "        LL[k] = np.sum(np.log(S)) - np.sum(C) #Store the log-likelihood of the key\n",
    "\n",
    "    k_guess = np.argsort(-LL)\n",
    "\n",
    "    t2 = time()\n",
    "\n",
    "    return k_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template LIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This implements the  template attck with linear leakage model.\n",
    "\n",
    "Input:\n",
    "    T         : the plaintext used for the considered Traces\n",
    "    Y         : the two shares of the leakage\n",
    "    sigma     : the noise level\n",
    "    tolerance : a threshold to decide when to stopp the while loop\n",
    "    N         : number of bits targeted\n",
    "    a_1,...   : parameters of the template to use\n",
    "\n",
    "Output:\n",
    "    k_guess   : the key hypothesis ranked by deacreasing goodness of fit with the model\n",
    "\"\"\"\n",
    "def template2(T,Y,sigma=np.reshape(np.array([1,1]),(2,1)),a_1=np.ones(4),b_1=0,a_2=np.ones(4),b_2=0,N=4):\n",
    "\n",
    "    a1=a_1/(2 ** .5 * sigma[0])\n",
    "    a2=a_2/(2 ** .5 * sigma[1])\n",
    "    b1=b_1/(2 ** .5 * sigma[0])\n",
    "    b2=b_2/(2 ** .5 * sigma[1])\n",
    "\n",
    "    Q = len(T)\n",
    "    Y/=(2 ** .5 * sigma)\n",
    "\n",
    "    y_bar = np.mean(Y,axis=1) #Precompute the average of the traces\n",
    "    LL = np.zeros(2**N) #To store the log-likelihood of each key hypothesis\n",
    "\n",
    "    Text,Mask = np.uint8(np.meshgrid(T, M))\n",
    "\n",
    "    X2 = np.reshape(np.unpackbits(Mask),(2**N,Q,8))[:,:,8-N:8]\n",
    "\n",
    "    for k in range(2**N):\n",
    "\n",
    "        X1 = np.reshape(np.unpackbits(Sbox(k^Text)^Mask),(2**N,Q,8))[:,:,8-N:8]\n",
    "        Norm = (Y[0,:]-np.dot(X1,a1)-b1)**2+(Y[1,:]-np.dot(X2,a2)-b2)**2\n",
    "        C = np.min(Norm,axis=0) #For numerical stabiblity of the exponnetial\n",
    "        beta = np.exp(C-Norm)\n",
    "        S  = np.sum(beta,axis=0) #Normalisation coefficient\n",
    "\n",
    "        LL[k] = np.sum(np.log(S)) - np.sum(C) #Store the log-likelihood of the key\n",
    "\n",
    "\n",
    "    k_guess = np.argsort(-LL)\n",
    "    return k_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template QUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This implements a template attack with quadratic leakage model.\n",
    "Input:\n",
    "    T      : the plaintext used for the considered traces.\n",
    "    Y      : the traces\n",
    "    sigma  : the noise level\n",
    "    Cvec0  : model parameters (Quadratic form of the first share)\n",
    "    Cvec1  : model parameters (Quadratic form of the second share)\n",
    "\"\"\"\n",
    "def template_quadratic(T,Y,sigma,Cvec0,Cvec1):\n",
    "\n",
    "    Q = len(T)\n",
    "\n",
    "    Y/=(2 ** .5 * sigma)\n",
    "    Cvec0/=(2 ** .5 * sigma[0])\n",
    "    Cvec1/=(2 ** .5 * sigma[1])\n",
    "\n",
    "    LL = np.zeros(2**N) #To store the log-likelihood of each key hypothesis\n",
    "    Text,Mask = np.meshgrid(T,M, copy = False)\n",
    "    X0 = np.unpackbits(Mask).reshape((2**N,Q,8))[:,:,8-N:8]\n",
    "\n",
    "    for k in range(2**N):\n",
    "        X1 = np.unpackbits(Sbox(k^Text)^Mask).reshape((2**N,Q,8))[:,:,8-N:8]\n",
    "\n",
    "        # Precompute the Quadratic Form\n",
    "        f0 = evaluate(Cvec0,X0).reshape((Q,2**N))\n",
    "        f1 = evaluate(Cvec1,X1).reshape((Q,2**N))\n",
    "\n",
    "        Norm =  (Y[0].reshape((Q,1)) - f0)**2\n",
    "        Norm += (Y[1].reshape((Q,1)) - f1)**2 #Shape (Q,2**N)\n",
    "\n",
    "        Cc = np.min(Norm,axis=1).reshape((Q,1))#Most likely mask for each trace\n",
    "        beta = np.exp(Cc-Norm) #Gaussian Kernel with shape (Q,2**N)\n",
    "        S  = np.sum(beta,axis=1) #Normalisation coefficient in Bayes\n",
    "\n",
    "        LL[k] = np.sum(np.log(S)) - np.sum(Cc) #Store the log-likelihood of the key\n",
    "    k_guess = np.argsort(-LL)\n",
    "\n",
    "    return k_guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
